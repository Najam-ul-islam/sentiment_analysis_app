{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/datacoding/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/datacoding/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/datacoding/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/datacoding/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"vader_lexicon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>Followers</th>\n",
       "      <th>retweets</th>\n",
       "      <th>tweets</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>url</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BilawalBhuttoZardari</td>\n",
       "      <td>5100000</td>\n",
       "      <td>4035</td>\n",
       "      <td>For the first time in the history of Karachi, ...</td>\n",
       "      <td>2023-06-19 15:29:00+00:00</td>\n",
       "      <td>1.670000e+18</td>\n",
       "      <td>https://twitter.com/BBhuttoZardari/status/1670...</td>\n",
       "      <td>@BBhuttoZardari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BilawalBhuttoZardari</td>\n",
       "      <td>5100000</td>\n",
       "      <td>5577</td>\n",
       "      <td>Thanks Swat! üôèüèΩ üôèüèΩ\\nToday, we come together to...</td>\n",
       "      <td>2023-06-17 16:38:00+00:00</td>\n",
       "      <td>1.670000e+18</td>\n",
       "      <td>https://twitter.com/BBhuttoZardari/status/1670...</td>\n",
       "      <td>@BBhuttoZardari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BilawalBhuttoZardari</td>\n",
       "      <td>5100000</td>\n",
       "      <td>4118</td>\n",
       "      <td>My Depest Sympathies With the Families of the ...</td>\n",
       "      <td>2023-06-17 11:09:00+00:00</td>\n",
       "      <td>1.670000e+18</td>\n",
       "      <td>https://twitter.com/BBhuttoZardari/status/1670...</td>\n",
       "      <td>@BBhuttoZardari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BilawalBhuttoZardari</td>\n",
       "      <td>5100000</td>\n",
       "      <td>4757</td>\n",
       "      <td>I thank the Members of Asia Pacific Group at u...</td>\n",
       "      <td>2023-06-22 11:51:00+00:00</td>\n",
       "      <td>1.670000e+18</td>\n",
       "      <td>https://twitter.com/BBhuttoZardari/status/1671...</td>\n",
       "      <td>@BBhuttoZardari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BilawalBhuttoZardari</td>\n",
       "      <td>5100000</td>\n",
       "      <td>4881</td>\n",
       "      <td>Our party has always strived for, and Led the ...</td>\n",
       "      <td>2023-06-16 17:38:00+00:00</td>\n",
       "      <td>1.670000e+18</td>\n",
       "      <td>https://twitter.com/BBhuttoZardari/status/1669...</td>\n",
       "      <td>@BBhuttoZardari</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               fullname  Followers  retweets  \\\n",
       "0  BilawalBhuttoZardari    5100000      4035   \n",
       "1  BilawalBhuttoZardari    5100000      5577   \n",
       "2  BilawalBhuttoZardari    5100000      4118   \n",
       "3  BilawalBhuttoZardari    5100000      4757   \n",
       "4  BilawalBhuttoZardari    5100000      4881   \n",
       "\n",
       "                                              tweets  \\\n",
       "0  For the first time in the history of Karachi, ...   \n",
       "1  Thanks Swat! üôèüèΩ üôèüèΩ\\nToday, we come together to...   \n",
       "2  My Depest Sympathies With the Families of the ...   \n",
       "3  I thank the Members of Asia Pacific Group at u...   \n",
       "4  Our party has always strived for, and Led the ...   \n",
       "\n",
       "                   timestamp      tweet_id  \\\n",
       "0  2023-06-19 15:29:00+00:00  1.670000e+18   \n",
       "1  2023-06-17 16:38:00+00:00  1.670000e+18   \n",
       "2  2023-06-17 11:09:00+00:00  1.670000e+18   \n",
       "3  2023-06-22 11:51:00+00:00  1.670000e+18   \n",
       "4  2023-06-16 17:38:00+00:00  1.670000e+18   \n",
       "\n",
       "                                                 url         username  \n",
       "0  https://twitter.com/BBhuttoZardari/status/1670...  @BBhuttoZardari  \n",
       "1  https://twitter.com/BBhuttoZardari/status/1670...  @BBhuttoZardari  \n",
       "2  https://twitter.com/BBhuttoZardari/status/1670...  @BBhuttoZardari  \n",
       "3  https://twitter.com/BBhuttoZardari/status/1671...  @BBhuttoZardari  \n",
       "4  https://twitter.com/BBhuttoZardari/status/1669...  @BBhuttoZardari  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"combined_data_all_new.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fullname           0\n",
       "Followers          0\n",
       "retweets           0\n",
       "tweets             0\n",
       "timestamp          0\n",
       "tweet_id           0\n",
       "url                0\n",
       "username           0\n",
       "cleaned_tweets     0\n",
       "sentiment_score    0\n",
       "sentiment_tag      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'duplicate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26308/2256583062.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5985\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5986\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5987\u001b[0m         ):\n\u001b[1;32m   5988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'duplicate'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "        text = str(text)\n",
    "        text = re.sub(r'@[A-Za-z0-9]+', '', text)  # remove mentions\n",
    "        text = re.sub(r'#', '', text)  # remove hashtags\n",
    "        text = re.sub(r'RT[\\s]+', '', text)  # remove retweets\n",
    "        text = re.sub(r'https?:\\/\\/\\S+', '', text)  # remove links\n",
    "        text = re.sub(r'[^A-Za-z0-9\\s]+', '', text)  # remove special characters\n",
    "       \n",
    "        return \" \".join(nltk.word_tokenize(text.lower().strip()))\n",
    "\n",
    "df[\"cleaned_tweets\"] = df[\"tweets\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    for the first time in the history of karachi i...\n",
       "1    thanks swat today we come together to maintain...\n",
       "2    my depest sympathies with the families of the ...\n",
       "3    i thank the members of asia pacific group at u...\n",
       "4    our party has always strived for and led the w...\n",
       "Name: cleaned_tweets, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"cleaned_tweets\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for the first time in the history of karachi i congratulate pakistan peoples partys barrister murtaza wahab on mayor karachi and salman abdullah murad on the oath of office it is hoped that the mayor karachi and deputy mayor karachi will deliver the city to new heights of development while serving the people of karachi'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"cleaned_tweets\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def analyze_sentiment(text):\n",
    "        \n",
    "        sid = SentimentIntensityAnalyzer()\n",
    "        sentiment_score = sid.polarity_scores(text)['compound']\n",
    "        sentiment_tag = 'positive' if sentiment_score > 0 else ('negative' if sentiment_score < 0 else 'neutral')\n",
    "        \n",
    "        return sentiment_score, sentiment_tag\n",
    "\n",
    "df['sentiment_score'], df['sentiment_tag'] = zip(*df['cleaned_tweets'].apply(analyze_sentiment))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>Followers</th>\n",
       "      <th>retweets</th>\n",
       "      <th>tweets</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>url</th>\n",
       "      <th>username</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BilawalBhuttoZardari</td>\n",
       "      <td>5100000</td>\n",
       "      <td>4035</td>\n",
       "      <td>For the first time in the history of Karachi, ...</td>\n",
       "      <td>2023-06-19 15:29:00+00:00</td>\n",
       "      <td>1.670000e+18</td>\n",
       "      <td>https://twitter.com/BBhuttoZardari/status/1670...</td>\n",
       "      <td>@BBhuttoZardari</td>\n",
       "      <td>for the first time in the history of karachi i...</td>\n",
       "      <td>0.7003</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BilawalBhuttoZardari</td>\n",
       "      <td>5100000</td>\n",
       "      <td>5577</td>\n",
       "      <td>Thanks Swat! üôèüèΩ üôèüèΩ\\nToday, we come together to...</td>\n",
       "      <td>2023-06-17 16:38:00+00:00</td>\n",
       "      <td>1.670000e+18</td>\n",
       "      <td>https://twitter.com/BBhuttoZardari/status/1670...</td>\n",
       "      <td>@BBhuttoZardari</td>\n",
       "      <td>thanks swat today we come together to maintain...</td>\n",
       "      <td>0.9666</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BilawalBhuttoZardari</td>\n",
       "      <td>5100000</td>\n",
       "      <td>4118</td>\n",
       "      <td>My Depest Sympathies With the Families of the ...</td>\n",
       "      <td>2023-06-17 11:09:00+00:00</td>\n",
       "      <td>1.670000e+18</td>\n",
       "      <td>https://twitter.com/BBhuttoZardari/status/1670...</td>\n",
       "      <td>@BBhuttoZardari</td>\n",
       "      <td>my depest sympathies with the families of the ...</td>\n",
       "      <td>-0.8720</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BilawalBhuttoZardari</td>\n",
       "      <td>5100000</td>\n",
       "      <td>4757</td>\n",
       "      <td>I thank the Members of Asia Pacific Group at u...</td>\n",
       "      <td>2023-06-22 11:51:00+00:00</td>\n",
       "      <td>1.670000e+18</td>\n",
       "      <td>https://twitter.com/BBhuttoZardari/status/1671...</td>\n",
       "      <td>@BBhuttoZardari</td>\n",
       "      <td>i thank the members of asia pacific group at u...</td>\n",
       "      <td>0.9062</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BilawalBhuttoZardari</td>\n",
       "      <td>5100000</td>\n",
       "      <td>4881</td>\n",
       "      <td>Our party has always strived for, and Led the ...</td>\n",
       "      <td>2023-06-16 17:38:00+00:00</td>\n",
       "      <td>1.670000e+18</td>\n",
       "      <td>https://twitter.com/BBhuttoZardari/status/1669...</td>\n",
       "      <td>@BBhuttoZardari</td>\n",
       "      <td>our party has always strived for and led the w...</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               fullname  Followers  retweets  \\\n",
       "0  BilawalBhuttoZardari    5100000      4035   \n",
       "1  BilawalBhuttoZardari    5100000      5577   \n",
       "2  BilawalBhuttoZardari    5100000      4118   \n",
       "3  BilawalBhuttoZardari    5100000      4757   \n",
       "4  BilawalBhuttoZardari    5100000      4881   \n",
       "\n",
       "                                              tweets  \\\n",
       "0  For the first time in the history of Karachi, ...   \n",
       "1  Thanks Swat! üôèüèΩ üôèüèΩ\\nToday, we come together to...   \n",
       "2  My Depest Sympathies With the Families of the ...   \n",
       "3  I thank the Members of Asia Pacific Group at u...   \n",
       "4  Our party has always strived for, and Led the ...   \n",
       "\n",
       "                   timestamp      tweet_id  \\\n",
       "0  2023-06-19 15:29:00+00:00  1.670000e+18   \n",
       "1  2023-06-17 16:38:00+00:00  1.670000e+18   \n",
       "2  2023-06-17 11:09:00+00:00  1.670000e+18   \n",
       "3  2023-06-22 11:51:00+00:00  1.670000e+18   \n",
       "4  2023-06-16 17:38:00+00:00  1.670000e+18   \n",
       "\n",
       "                                                 url         username  \\\n",
       "0  https://twitter.com/BBhuttoZardari/status/1670...  @BBhuttoZardari   \n",
       "1  https://twitter.com/BBhuttoZardari/status/1670...  @BBhuttoZardari   \n",
       "2  https://twitter.com/BBhuttoZardari/status/1670...  @BBhuttoZardari   \n",
       "3  https://twitter.com/BBhuttoZardari/status/1671...  @BBhuttoZardari   \n",
       "4  https://twitter.com/BBhuttoZardari/status/1669...  @BBhuttoZardari   \n",
       "\n",
       "                                      cleaned_tweets  sentiment_score  \\\n",
       "0  for the first time in the history of karachi i...           0.7003   \n",
       "1  thanks swat today we come together to maintain...           0.9666   \n",
       "2  my depest sympathies with the families of the ...          -0.8720   \n",
       "3  i thank the members of asia pacific group at u...           0.9062   \n",
       "4  our party has always strived for and led the w...           0.6705   \n",
       "\n",
       "  sentiment_tag  \n",
       "0      positive  \n",
       "1      positive  \n",
       "2      negative  \n",
       "3      positive  \n",
       "4      positive  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"cleaned_tweets\"]\n",
    "y = df[\"sentiment_tag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have preprocessed data and labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4795    heard with concern about hospitalisation of hi...\n",
       "289     pakistan strongly condemns the insensitive and...\n",
       "2589                                       i am on my way\n",
       "4126    the details of reservations on the amendments ...\n",
       "4494    preparing a cricket ground for the youngsters ...\n",
       "                              ...                        \n",
       "4426    saddened to learn of rahimullah yousafzais pas...\n",
       "466     heartest felications to president xi on which ...\n",
       "3092    from every citizen especially those who will e...\n",
       "3772    after informing the president about the danger...\n",
       "860     renala khurd ki awaam ka faisla puppet pm par ...\n",
       "Name: cleaned_tweets, Length: 3880, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(solver=\"lbfgs\")\n",
    "model.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7971163748712667\n"
     ]
    }
   ],
   "source": [
    "#  Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Generate a classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Save the model and its results\n",
    "saved_model = {\n",
    "    \"model\": model,\n",
    "    \"vectorizer\": vectorizer,\n",
    "    \"accuracy\": accuracy,\n",
    "    \"classification_report\": class_report\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.76      0.77       335\n",
      "     neutral       0.81      0.80      0.81       208\n",
      "    positive       0.80      0.82      0.81       428\n",
      "\n",
      "    accuracy                           0.80       971\n",
      "   macro avg       0.80      0.79      0.80       971\n",
      "weighted avg       0.80      0.80      0.80       971\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logestics_regression_model.pkl']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(saved_model, \"logestics_regression_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = joblib.load(\"logestics_regression_model.pkl\")\n",
    "\n",
    "# Get the loaded model and vectorizer\n",
    "model = loaded_model[\"model\"]\n",
    "vectorizer = loaded_model[\"vectorizer\"]\n",
    "\n",
    "# Get user input\n",
    "user_input = input(\"Enter a tweet: \")\n",
    "\n",
    "# Preprocess the user input\n",
    "cleaned_input = clean_text(user_input)  # You need to define preprocess_text function\n",
    "\n",
    "# Vectorize the preprocessed input\n",
    "input_vector = vectorizer.transform([cleaned_input])\n",
    "\n",
    "# Make a prediction\n",
    "prediction = model.predict(input_vector)\n",
    "\n",
    "# Print the sentiment prediction\n",
    "print(\"Predicted Sentiment:\", prediction[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.8053553038105047\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create an SVM model\n",
    "svm_model = SVC(kernel='linear')\n",
    "\n",
    "# Train the SVM model\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "svm_predictions = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "\n",
    "print(\"SVM Accuracy:\", svm_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logistic_regression_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mensemble\u001b[39;00m \u001b[39mimport\u001b[39;00m VotingClassifier\n\u001b[1;32m      3\u001b[0m \u001b[39m# Create a list of models\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m models \u001b[39m=\u001b[39m [(\u001b[39m'\u001b[39m\u001b[39mlogreg\u001b[39m\u001b[39m'\u001b[39m, logistic_regression_model), (\u001b[39m'\u001b[39m\u001b[39msvm\u001b[39m\u001b[39m'\u001b[39m, svm_model), (\u001b[39m'\u001b[39m\u001b[39mrf\u001b[39m\u001b[39m'\u001b[39m, random_forest_model)]\n\u001b[1;32m      6\u001b[0m \u001b[39m# Create a VotingClassifier\u001b[39;00m\n\u001b[1;32m      7\u001b[0m voting_classifier \u001b[39m=\u001b[39m VotingClassifier(estimators\u001b[39m=\u001b[39mmodels, voting\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhard\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logistic_regression_model' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Create a list of models\n",
    "models = [('logreg', logistic_regression_model), ('svm', svm_model), ('rf', random_forest_model)]\n",
    "\n",
    "# Create a VotingClassifier\n",
    "voting_classifier = VotingClassifier(estimators=models, voting='hard')\n",
    "\n",
    "# Train the VotingClassifier\n",
    "voting_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions using the VotingClassifier\n",
    "ensemble_predictions = voting_classifier.predict(X_test_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Define a range of hyperparameters to search\n",
    "# param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2']}\n",
    "\n",
    "# # Create a grid search object\n",
    "# grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "\n",
    "# # Fit the grid search to your data\n",
    "# grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# # Get the best hyperparameters\n",
    "# best_params = grid_search.best_params_\n",
    "# print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from scipy.stats import uniform\n",
    "\n",
    "# # Define a distribution over hyperparameters\n",
    "# param_dist = {'C': uniform(0.001, 100), 'penalty': ['l1', 'l2']}\n",
    "\n",
    "# # Create a random search object\n",
    "# random_search = RandomizedSearchCV(LogisticRegression(), param_distributions=param_dist, n_iter=100, cv=5)\n",
    "\n",
    "# # Fit the random search to your data\n",
    "# random_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# # Get the best hyperparameters\n",
    "# best_params = random_search.best_params_\n",
    "# print(\"Best Hyperparameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the output on the user input text\n",
    "user_input = input(\"enter text: \")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
